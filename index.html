<html>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Chuanguang Yang</title>
    <meta content="Chuanguang Yang, https://winycg.github.io" name="keywords">
    <style media="screen" type="text/css">
        html,
        body,
        div,
        span,
        applet,
        object,
        iframe,
        h1,
        h2,
        h3,
        h4,
        h5,
        h6,
        p,
        blockquote,
        pre,
        a,
        abbr,
        acronym,
        address,
        big,
        cite,
        code,
        del,
        dfn,
        em,
        font,
        img,
        ins,
        kbd,
        q,
        s,
        samp,
        small,
        strike,
        strong,
        sub,
        tt,
        var,
        dl,
        dt,
        dd,
        ol,
        ul,
        li,
        fieldset,
        form,
        label,
        legend,
        table,
        caption,
        tbody,
        tfoot,
        thead,
        tr,
        th,
        td {
            border: 0pt none;
            font-family: Times New Roman;
            font-size: 100%;
            font-style: inherit;
            font-weight: inherit;
            margin: 0pt;
            outline-color: invert;
            outline-style: none;
            outline-width: 0pt;
            padding: 0pt;
            vertical-align: baseline;
        }

        a {
            color: #1772d0;
            text-decoration: none;
        }

        a:focus,
        a:hover {
            color: #f09228;
            text-decoration: none;
        }

        a.paper {
            font-weight: bold;
            font-size: 12pt;
        }

        b.paper {
            font-weight: bold;
            font-size: 12pt;
        }

        * {
            margin: 0pt;
            padding: 0pt;
        }

        body {
            position: relative;
            margin: 3em auto 2em auto;
            width: 1000px;
            font-family: Times New Roman;
            font-size: 16px;
            background: #eee;
        }

        h2 {
            font-family: Times New Roman;
            font-size: 16px;
            font-weight: 700;
        }

        h3 {
            font-family: Times New Roman;
            font-size: 16px;
            font-weight: 700;
        }

        strong {
            font-family: Times New Roman;
            font-size: 16px;
            font-weight: bold;
        }

        ul {
            list-style: circle;
        }

        img {
            border: none;
        }

        li {
            padding-bottom: 0.5em;
            margin-left: 1.4em;
        }

        alert {
            font-family: Times New Roman;
            font-size: 20px;
            font-weight: bold;
            color: #FF0000;
        }

        em,
        i {
            font-style: italic;
        }

        div.section {
            clear: both;
            margin-bottom: 1.5em;
            background: #eee;
        }

        div.spanner {
            clear: both;
        }

        div.paper {
            clear: both;
            margin-top: 0.5em;
            margin-bottom: 1em;
            border: 1px solid #ddd;
            background: #fff;
            padding: 1em 1em 1em 1em;
        }

        div.paper div {
            padding-left: 230px;
        }

        img.paper {
            margin-bottom: 0.5em;
            float: left;
            width: 200px;
        }

        span.blurb {
            font-style: italic;
            display: block;
            margin-top: 0.75em;
            margin-bottom: 0.5em;
        }

        pre,
        code {
            font-family: 'Lucida Console', 'Andale Mono', 'Courier', monospaced;
            margin: 1em 0;
            padding: 0;
        }

        div.paper pre {
            font-size: 0.9em;
        }

        /* navigation bar */
/* 导航栏 */
.navbar {
    display: flex; /* 使用flex布局 */
    align-items: center; /* 垂直居中 */
    background-color: #0156a3;
    position: fixed; /* fix to the top of the page. 固定在页面顶部 */
    top: 0;
    left: 0; /* 确保从最左边开始 */
    right: 0; /* 确保延伸到最右边 */
    width: 100%;
    height: 45px;
    z-index: 1000; /* ensure the navigation bar is above other content. 保证导航栏在其他内容之上 */
    padding: 0 11%; /* 添加一些内边距 */
    box-sizing: border-box; /* 确保padding包含在width内 */
}

.navbar-logo {
    display: flex;
    align-items: center;
    height: 100%;
    margin-right: 4%; /*图片和链接之间的间距*/
}

.navbar-logo img {
    height: 80%; /* 固定图片高度 */
    width: auto; /* 保持宽高比 */
}

.navbar-links {
    display: flex;
    height: 100%;
    align-items: center;
    flex-grow: 1; /* 让链接区域占据剩余空间 */
    justify-content: flex-start; /* 左对齐 */
    overflow-x: auto; /* 允许横向滚动 */
    white-space: nowrap; /* 防止换行 */
}

/* 修改链接项 */
.navbar-links a {
    display: inline-flex; /* 改为inline-flex */
    align-items: center;
    color: white;
    padding: 0 15px; /* 减少左右padding */
    height: 100%;
    text-decoration: none;
    font-size: 18px;
    scroll-margin-top: 100px;
}

/* effect on mouse hover */
/* 鼠标悬停时的效果 */
.navbar a:hover {
    background-color: #002D72;
    color: white;
    height: 100%;
}

.more-button {
    background: none;
    border: 1px solid #0156a3;
    color: #0156a3;
    padding: 5px 10px 5px 10px;
    border-radius: 4px;
    cursor: pointer;
    transition: all 0.3s;
    margin: 0px 0px 0px 0px;
    margin-left: 10px;
}

.more-button:hover {
    background: #0156a3;
    color: white;
}

.more-button i {
    margin-left: 5px;
    transition: transform 0.3s;
}

.news-list li.more-news {
    display: none;
    padding-left: 4em;
    text-indent: -4.5em;
}


    </style>

    <link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet"
          type="text/css"/>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-164510176-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-164510176-1');

      document.addEventListener('DOMContentLoaded', function() {
    document.addEventListener('click', function(e) {
        if (e.target && e.target.id === 'more-news-btn') {
            const hiddenItems = document.querySelectorAll('.more-news');
            let allVisible = true;
            
            hiddenItems.forEach(item => {
                if (item.style.display === 'none') {
                    allVisible = false;
                }
            });
            
            hiddenItems.forEach(item => {
                item.style.display = allVisible ? 'none' : 'list-item';
            });
            
            if (allVisible) {
                e.target.innerHTML = 'More News <i class="fas fa-chevron-down"></i>';
                e.target.classList.remove('active');
            } else {
                e.target.innerHTML = 'Less News <i class="fas fa-chevron-up"></i>';
                e.target.classList.add('active');
            }
        }
    });
});
    </script>

</head>


<body>

<!-- Navigation bar -->
<div class="navbar">
    <div class="navbar-logo">
        <a href="index.html"><img src="./resources/images/ict.png"></a>
    </div>
    <div class="navbar-links">
        <a href="#research_interests">Research Interests</a>
        <a href="#news">News</a>
        <a href="#Recruiting">Recruiting</a>
        <a href="#confpapers">Publications</a>
        <a href="#funding">Funding</a>
        <!-- <a href="/html/record.html" class="record-button" id="recordButton">Record</a> -->
    </div>
</div>

<div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 180px;">
    <div style="margin: 0px auto; width: 100%;">
        <img title="implus" style="float: left; padding-left: .01em; height: 140px;"
             src="./resources/images/me.jpg">
        <div style="padding-left: 10em; vertical-align: top; height: 180px;">
            <span style="line-height: 150%; font-size: 20pt;">Chuanguang Yang (杨传广)</span><br>
            <span> Institute of Computing Technology, Chinese Academy of Sciences (ICT, CAS)</span><br>
<span><strong>Address</strong>: No.6 Kexueyuan South Road Zhongguancun,Haidian District Beijing,China</span><br>
            <span><strong>Email</strong>: yangchuanguang@ict.ac.cn </span> <br>
            <span> <a href="https://blog.csdn.net/winycg">Blog</a></span> |
            <span> <a href="https://github.com/winycg">GitHub</a></span> |
            <span> <a href="https://scholar.google.com/citations?user=gYyDQqAAAAAJ">Google Scholar</a></span>
            <br>
            I am an assistant professor (researcher) at the <a href="http://english.ict.cas.cn/rese/divi/net/202302/t20230209_326883.html">Domain-Oriented Intelligent System Research Center</a>, from <a href="http://www.ict.ac.cn/">Institute of Computing Technology, Chinese Academy of Sciences</a> (2023.7~now). 
            I got my Ph.D. degree from Institute of Computing Technology, Chinese Academy of Sciences (2018.9~2023.6), supervised by <a href="https://scholar.google.com/citations?user=daBvGcMAAAAJ">Prof. Zhulin An</a> and <a href="https://scholar.google.com/citations?user=l34KxTYAAAAJ">Prof. Yongjun Xu</a>. 
        </div>
    </div>
</div>
<!--<div style="clear: both; background-color: #fff; margin-top: 1.5em; padding: .2em; padding-left: .3em;">-->


<div style="clear: both;"></div>
    <div class="section">
        <h2 id="research_interests">Research Interests
        </h2>
        <div class="paper">
            <ul>
                <li>Knowledge distillation for visual recognition models (e.g. image classification, object detection, semantic segmenation), visual generative models (e.g. diffusion),
                    and multi-modal models (e.g. CLIP);</li>
                    <li>Prompt learning for applying multi-modal large models to downstream visual recognition tasks; </li>
                    <li>Image generation and editing based on Stable Diffusion;</li>
                <li>Other model compression techniques, including but not limited to efficient network architecture design, pruning, quantization and dynamic inference; </li>
            </ul>

        </div>
    </div>
</div>



<div style="clear: both;"></div>
    <div class="section">
        <h2 id="Recruiting">Recruiting <button class="more-button" id="changeButtonChinese">中文版</button><button  class="more-button" id="changeButtonEnglish">English</button>
        </h2>
        <div class="paper">
            <p id="textToChange" style="white-space: pre-line;">【硕士/博士招生】课题组每年有1~2个硕士名额，1个博士名额。请关注计算所7月的保研夏令营暑期班、9月的保研考核和3月的考研考核 
            【实习】课题组有1~2名实习生名额，可以线上和线下，如果有兴趣请邮件联系</p>
            
            

        <script>
        document.getElementById('changeButtonChinese').addEventListener('click', function() {
            document.getElementById('textToChange').textContent = '【硕士/博士招生】课题组每年有1~2个硕士名额，1个博士名额。请关注计算所7月的保研夏令营暑期班、9月的保研考核和3月的考研考核 \n 【实习】课题组有1~2名实习生名额，可以线上和线下，如果有兴趣请邮件联系';
        });
        document.getElementById('changeButtonEnglish').addEventListener('click', function() {
            document.getElementById('textToChange').textContent = '[Master or Ph.D. positions]: we have 1~2 Master and 1 Ph.D. admission quotas annually. Please pay attention to the July summer camp for postgraduate recommendation at ICT, the September postgraduate recommendation assessment, and the March postgraduate entrance examination. \n [Internship]: we have 1~2 openings for interns. Both onsite and offsite are welcome. Please send me an email with your resume if you are interested.';
        });
        </script>
        </div>
    </div>
</div>


<div style="clear: both;">
    <div class="section">
        <h2 id="news">News</h2>
        <div class="paper">
            <ul>
                <li>
                    [2025.5] One paper was accepted by KDD-2025
                </li>
                <li>
                    [2025.5] Two papers were accepted by ICML-2025
                </li>
                <li>
                    [2025.2] One paper was accepted by CVPR-2025
                </li>
                <li>
                    [2025.1] Three papers were accepted by AAAI-2025
                </li>
                <li>
                    [2024.7] One paper was accepted by ACM MM-2024
                </li>
                <li>
                    [2024.5] One paper was accepted by ICML-2024
                </li>
                <li>
                    [2024.2] One paper was accepted by CVPR-2024
                </li>
                <li class="more-news" style="display:none;">
                    [2023.7] One paper was accepted by ICCV-2023
                </li>
                <li class="more-news" style="display:none;">
                    [2023.3] One paper was accepted by TPAMI-2023
                </li>
                <li class="more-news" style="display:none;">
                    [2023.2] Invited review paper was accepted as the first chapter of the book《Advancements in Knowledge Distillation: Towards New Horizons of Intelligent Systems》by Springer Nature
                </li>
                <li class="more-news" style="display:none;">
                    [2022.12.7] Invited talk of "VL-Match: Enhancing Vision-Language Pretraining with Token-Level and Instance-Level Matching" at Microsoft Bing
                </li>
                <li class="more-news" style="display:none;">
                    [2022.11.15] Invited talk of "Multi-Modal Knowledge Distillation: Survey and Outlook" at MSRA
                </li>
                <li class="more-news" style="display:none;">
                    [2022.7.22] Served as a session chair of ICME-2022 Oral 36 Semantic Segmentation IV.
                </li>
                <li class="more-news" style="display:none;">
                    [2022.7] One paper was accepted by ECCV-2022
                </li>
                <li class="more-news" style="display:none;">
                    [2022.6] One paper was accepted by TNNLS-2022
                </li>
                <li class="more-news" style="display:none;">
                    [2022.4.14] Invited talk of "Knowledge Distillation: Survey and Outlook" at Gaoling School of Artificial Intelligence, Renmin University of China
                </li>
                <li class="more-news" style="display:none;">
                    [2022.3.11] Invited talk of our CVPR-2022 paper "Cross-image Relational Knowledge Distillation for Semantic Segmentation" at Horizon Robotics
                </li>
                <li class="more-news" style="display:none;">
                    [2022.3] One paper was accepted by CVPR-2022
                </li>
                <li class="more-news" style="display:none;">
                    [2022.1.21] Invited talk about "Self-supervised Contrastive Learning" at Horizon Robotics
                </li>
                <li class="more-news" style="display:none;">
                    [2021.12] Two papers were accepted by AAAI-2022
                </li>
                <li class="more-news" style="display:none;">
                    [2021.9.16] Invited talk of our IJCAI-2021 paper "Hierarchical Self-supervised Augmented Knowledge Distillation" by AI Drive and Paper weekly
                </li>
                <li class="more-news" style="display:none;">
                    [2021.4] One paper was accepted by IJCAI-2021
                </li>
                <li class="more-news" style="display:none;">
                    [2020.6.21] Invited talk of our AAAI-2020 paper "Gated Convolutional Networks with Hybrid Connectivity for Image Classification" by Student Forum on Frontiers of Artificial Intelligence (SFFAI)
                </li>
                <li class="more-news" style="display:none;">
                    [2019.11] One paper was accepted by AAAI-2020
                </li>
            </ul>
            <button id="more-news-btn" class="more-button"> More News <i class="fas fa-chevron-down"></i></button>
            <div class="spanner"></div>
        </div>
    </div>
</div>


<div style="clear: both;">
    <div class="section">
        <h2 id="confpapers">Publications [<a href="publication.html">Details</a>]</h2>
        <div class="paper">
            <ul>
                * represents corresponding author, † represents co-first author.
                <h3>2025</h3>
                <li>
                    Han Yang, <strong><font color="blue">Chuanguang Yang</font></strong>*, Qiuli Wang, Zhulin An*, Weilun Feng, Libo Huang, Yongjun Xu.
                    <br/>
                    Multi-party Collaborative Attention Control for Image Customization.
                    <br/>
                    <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition</i> <strong>(CVPR-2025)</strong> [<alert>CCF-A</alert>]<br>
                </li>
                <li>
                    Han Yang, <strong><font color="blue">Chuanguang Yang</font></strong>*, Zhulin An*, Libo Huang, Yongjun Xu.
                    <br/>
                    HSRDiff: A Hierarchical Self-Regulation Diffusion Model for Stochastic Semantic Segmentation.
                    <br/>
                    <i>AAAI Conference on Artificial Intelligence</i> <strong>(AAAI-2025)</strong> [<alert>CCF-A</alert>]<br>
                </li>
                <li>
                    Weilun Feng†, Haotong Qin†, <strong><font color="blue">Chuanguang Yang</font></strong>*, Zhulin An*, Libo Huang, Boyu Diao, Fei Wang, Renshuai Tao, Yongjun Xu, Michele Magno.
                    <br/>
                    MPQ-DM: Mixed Precision Quantization for Extremely Low Bit Diffusion Models.
                    <br/>
                    <i>AAAI Conference on Artificial Intelligence</i> <strong>(AAAI-2025)</strong> [<alert>CCF-A</alert>]<br>
                </li>
                <li>
                    <strong><font color="blue">Chuanguang Yang</font></strong>, Xinqiang Yu, Han Yang, Zhulin An*, Chengqing Yu, Libo Huang, Yongjun Xu.
                    <br/>
                    Multi-Teacher Knowledge Distillation with Reinforcement Learning for Visual Recognition.
                    <br/>
                    <i>AAAI Conference on Artificial Intelligence</i> <strong>(AAAI-2025)</strong> [<alert>CCF-A</alert>]<br>
                </li>
                <h3>2024</h3>
                <li>
                    Weilun Feng, <strong><font color="blue">Chuanguang Yang</font></strong>*, Zhulin An*, Libo Huang, Boyu Diao, Fei Wang, Yongjun Xu.
                    <br/>
                    Relational Diffusion Distillation For Efficient Image Generation.
                    <br/>
                    <i>ACM Multimedia</i> <strong>(ACM MM-2024)</strong> [<alert>CCF-A</alert>]<br>
                </li>
                <li>
                    Lujun Li, Yufan Bao, Peijie Dong, <strong><font color="blue">Chuanguang Yang</font></strong>, Anggeng Li, Wenhan Luo, Qifeng Liu, Wei Xue, Yike Guo.
                    <br/>
                    DetKDS: Knowledge Distillation Search for Object Detectors.
                    <br/>
                    <i>International Conference on Machine Learning </i> <strong>(ICML-2024)</strong> [<alert>CCF-A</alert>]<br>
                </li>
                <li>
                    Xinqiang Yu, <strong><font color="blue">Chuanguang Yang</font></strong>*, Chengqing Yu, Libo Huang*, Zhulin An*, Yongjun Xu.
                    <br/>
                    Online Policy Distillation with Decision-Attention.
                    <br/>
                    <i>International Joint Conference on Neural Networks </i> <strong>(IJCNN-2024)</strong> [<alert>CCF-C</alert>]<br>
                </li>
                <li>
                    <strong><font color="blue">Chuanguang Yang</font></strong>, Zhulin An*, Libo Huang, Junyu Bi, Xinqiang Yu, Han Yang, Boyu Diao, Yongjun Xu*.
                    <br/>
                    CLIP-KD: An Empirical Study of CLIP Model Distillation.
                    <br/>
                    <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition </i> <strong>(CVPR-2024)</strong> [<alert>CCF-A</alert>]<br>
                </li>
                <li>
                    <strong><font color="blue">Chuanguang Yang</font></strong>, Luming Chen*, Erhu Zhao, Zhulin An, Yongjun Xu.
                    <br/>
                    Graph-based Representation Knowledge Distillation for Image Classification. (基于图表征知识蒸馏的图像分类方法)
                    <br/>
                    <i>Acta Electronica Sinica</i> <strong>(电子学报)</strong> [<alert>CCF-A</alert>]<br>
                </li>
                <li>
                    Libo Huang, Yan Zeng, <strong><font color="blue">Chuanguang Yang</font></strong>, Zhulin An*, Boyu Diao, Yongjun Xu.
                    <br/>
                    eTag: Class-Incremental Learning with Embedding Distillation and Task-Oriented Generation.
                    <br/>
                    <i>AAAI Conference on Artificial Intelligence</i> <strong>(AAAI-2024)</strong> [<alert>CCF-A</alert>]<br>
                </li>
                
                <h3>2023</h3>
                
                <li>
                    Junyu Bi, Daixuan Cheng, Ping Yao*, Bochen Pang, Yuefeng Zhan, <strong><font color="blue">Chuanguang Yang</font></strong> et al.
                    <br/>
                    VL-Match: Enhancing Vision-Language Pretraining with Token-Level and Instance-Level Matching.
                    <br/>
                    <i>IEEE/CVF International Conference on Computer Vision </i> <strong>(ICCV-2023)</strong> [<alert>CCF-A</alert>]<br>
                </li>
                <li>
                    <strong><font color="blue">Chuanguang Yang</font></strong>*, Xinqiang Yu, Zhulin An, Yongjun Xu.
                    <br/>
                    Categories of Response-Based, Feature-Based, and Relation-Based Knowledge Distillation.
                    <br/>
                    <i>Advancements in Knowledge Distillation: Towards New Horizons of Intelligent Systems </i> <strong>(Springer Book Chapter)</strong><br>
                </li>
                <li>
                    <strong><font color="blue">Chuanguang Yang</font></strong>, Zhulin An*, Helong Zhou, Fuzhen Zhuang, Yongjun Xu, Qian Zhang.
                    <br/>
                    Online Knowledge Distillation via Mutual Contrastive Learning for Visual Recognition.
                    <br/>
                    <i>IEEE Transactions on Pattern Analysis and Machine Intelligence </i> <strong>(TPAMI-2023)</strong> [<alert>CCF-A</alert>]<br>
                </li>
                <h3>2022</h3>
                <li>
                    <strong><font color="blue">Chuanguang Yang</font></strong>, Zhulin An*, Helong Zhou, Linhang Cai, Xiang Zhi, Jiwen Wu, Yongjun Xu, Qian Zhang.
                    <br/>
                    MixSKD: Self-Knowledge Distillation from Mixup for Image Recognition.
                    <br/>
                    <i>European Conference on Computer Vision </i> <strong>(ECCV-2022)</strong> [<alert>CCF-B</alert>]<br>
                </li>
                <li>
                    <strong><font color="blue">Chuanguang Yang</font></strong>, Zhulin An*, Linhang Cai, Yongjun Xu.
                    <br/>
                    Knowledge Distillation Using Hierarchical Self-Supervision Augmented Distribution.
                    <br/><i>IEEE Transactions on Neural Networks and Learning Systems</i>
                    <strong>(TNNLS-2022)</strong>[<alert>CCF-B, IF:14.255</alert>]<br>
                </li>
                <li>
                    <strong><font color="blue">Chuanguang Yang</font></strong>, Zhulin An*, Yongjun Xu. 
                    <br/>
                    Localizing Semantic Patches for Accelerating Image Classification.
                    <br/>
                    <i>IEEE International Conference on Multimedia and Expo</i> <strong>(ICME-2022)</strong> [<alert>CCF-B</alert>]<br>
                </li>
                <li>
                    <strong><font color="blue">Chuanguang Yang</font></strong>, Helong Zhou, Zhulin An*, Xue Jiang, Yongjun Xu, Qian Zhang.
                    <br/>
                    Cross-Image Relational Knowledge Distillation for Semantic Segmentation. 
                    <br/>
                    <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition </i> <strong>(CVPR-2022)</strong> [<alert>CCF-A</alert>]<br>
                </li>
                <li>
                    <strong><font color="blue">Chuanguang Yang</font></strong>, Zhulin An*, Linhang Cai, Yongjun Xu. 
                    <br/>
                    Mutual Contrastive Learning for Visual Representation Learning.
                    <br/>
                    <i>AAAI Conference on Artificial Intelligence</i> <strong>(AAAI-2022)</strong> [<alert>CCF-A</alert>]<br>
                </li>
                <li>
                    Linhang Cai, Zhulin An*, <strong><font color="blue">Chuanguang Yang</font></strong>, Yanchun Yang, Yongjun Xu.
                    <br/>
                    Prior Gradient Mask Guided Pruning-aware Fine-tuning. <br/>
                    <i>AAAI Conference on Artificial Intelligence</i> <strong>(AAAI-2022)</strong> [<alert>CCF-A</alert>]<br>
                </li>
                <h3>2021</h3>
                <li>
                    <strong><font color="blue">Chuanguang Yang</font></strong>, Zhulin An*, Linhang Cai, Yongjun Xu. <br/>
                    Hierarchical Self-supervised Augmented Knowledge Distillation. <br/><i>International Joint Conference on Artificial Intelligence</i>
                    <strong>(IJCAI-2021)</strong> [<alert>CCF-A</alert>]<br>
                </li>
                <li>
                    <strong><font color="blue">Chuanguang Yang</font></strong>, Zhulin An*, Yongjun Xu.<br/> Multi-View Contrastive Learning for Online Knowledge Distillation.
                    <br/>
                    <i>IEEE International Conference on Acoustics, Speech and Signal Processing</i>
                    <strong>(ICASSP-2021)</strong> [<alert>CCF-B</alert>]<br>
                </li>
                <li>
                    Linhang Cai, Zhulin An*, <strong><font color="blue">Chuanguang Yang</font></strong>, Yongjun Xu.<br/>
                    Soft and Hard Filter Pruning via Dimension Reduction.<br/>
                    <i>International Joint Conference on Neural Networks</i> 
                    <strong>(IJCNN-2021)</strong> [<alert>CCF-C</alert>]<br>
                </li>
                <h3>2020</h3>
                <li>
                    Linhang Cai, Zhulin An*, <strong><font color="blue">Chuanguang Yang</font></strong>, Yongjun Xu.<br>
                    Softer Pruning, Incremental Regularization.<br>
                    <i>International Conference on Pattern Recognition</i> 
                    <strong>(ICPR-2020)</strong> [<alert>CCF-C</alert>]<br>
                </li>
                <li>
                    Hui Zhu, Zhulin An*, <strong><font color="blue">Chuanguang Yang</font></strong>, Xiaolong Hu, Kaiqiang Xu, Yongjun Xu. <br>
                    Efficient Search for the Number of Channels for Convolutional Neural Networks. <br>
                    <i>International Joint Conference on Neural Networks</i> 
                    <strong>(IJCNN-2020)</strong> [<alert>CCF-C</alert>]<br>
                </li>
                <li>
                    Xiaolong Hu, Zhulin An*, <strong><font color="blue">Chuanguang Yang</font></strong>, Hui Zhu, Kaiqaing Xu, Yongjun Xu. <br>
                    DRNet: Dissect and Reconstruct the Convolutional Neural Network via Interpretable Manners. <br>
                    <i>European Conference on Artificial Intelligence</i> 
                    <strong>(ECAI-2020)</strong> [<alert>CCF-B</alert>]<br>
                </li>
                <li>
                    <strong><font color="blue">Chuanguang Yang</font></strong>, Zhulin An*, Hui Zhu, Xiaolong Hu, Kun Zhang, Kaiqiang Xu, Chao Li, Yongjun Xu.<br>
                    Gated Convolutional Networks with Hybrid Connectivity for Image Classification. <br>
                    <i>AAAI Conference on Artificial Intelligence</i> 
                    <strong>(AAAI-2020)</strong> [<alert>CCF-A</alert>]<br>
                </li>
                <h3>2019</h3>
                <li>
                    Hui Zhu, Zhulin An*, <strong><font color="blue">Chuanguang Yang</font></strong>, Kaiqiang Xu, Erhu Zhao, Yongjun Xu.<br>
                    EENA: Efficient Evolution of Neural Architecture.<br>
                    <i>International Conference on Computer Vision Workshops</i> 
                    <strong>(ICCVW-2019)</strong> [<alert>CCF-A Workshops</alert>]<br>
                </li>
                <li>
                    <strong><font color="blue">Chuanguang Yang</font></strong>, Zhulin An*, Chao Li, Boyu Diao, Yongjun Xu. <br>
                    Multi-objective Pruning for CNNs using Genetic Algorithm. <br>
                    <i>International Conference on Artificial Neural Networks</i> 
                    <strong>(ICANN-2019)</strong> [<alert>CCF-C</alert>]<br>
                </li>
                
            </ul>
            <div class="spanner"></div>
        </div>


        <div style="clear: both;">
            <div class="section">
                <h2>Review Services</h2>
                <div class="paper">
                    <ul>
                        <li>
                            Conference:
                            <br>
                            CVPR-2022~2025
                            <br>
                            ECCV-2022, 2024
                            <br>
                            ICCV-2023
                            <br>
                            AAAI-2022~2025
                            <br>
                            IJCAI-2023~2024
                            <br>
                            NeurIPS-2024~2025
                            <br>
                            ICLR-2025
                            <br>
                            ICML-2025
                            <br>
                            ACM MM-2021~2023
                            <br>
                            ACCV-2024
                        </li>
                        <li>
                            Journal:
                            <br>
                            IEEE Transactions on Neural Networks and Learning Systems
                            <br>
                            Applied Artificial Intelligence
                        </li>
                    </ul>
                </div>
            </div>
        </div>

        <div style="clear: both;">
            <div class="section">
                <h2 id="funding">Funding</h2>
                <div class="paper">
                    <ul>
                        <li>
                            Youth Science Fund of the National Natural Science Foundation of China
                            <br>
                            国家自然科学基金青年科学基金，经费30万
                        </li>
                        <li>
                            China National Postdoctoral Program for Innovative Talents
                            <br>
                            博士后创新人才支持计划，2024年度全国不限专业共500人，经费64万
                        </li>
                        <li>
                            Chinese Academy of Sciences Specific Research Assistant Funding Program
                            <br>
                            中国科学院特别研究助理资助项目，2023年度中科院计算所共6项
                        </li>
                    </ul>
                    <div class="spanner"></div>
                </div>
            </div>
        </div>


        <div style="clear: both;">
            <div class="section">
                <h2 id="confpapers">Honor</h2>
                <div class="paper">
                    <ul>
                        <li>
                            CCF Doctoral Dissertation Incentive Program Nomination (CCF博士学位论文激励计划提名), 2024
                        </li>
                        <li>
                            Top One Hundred New Star of ICT (中科院计算所新百星), 2024
                        </li>
                        <li>
                            Class A of Specific Assistant Researcher (特别研究助理A类), 2024
                        </li>
                        <li>
                            Special Prize of President Scholarship, Chinese Academy of Sciences (中国科学院院长特别奖), 2023, [2023年度计算所仅1项，为中国科学院对在学研究生的最高奖励]
                        </li>
                        <li>
                            National Scholarship (研究生国家奖学金), 2020
                        </li>
                        <li>
                            President's Scholarship of ICT (中科院计算所所长奖学金), 2020
                        </li>
                        <li>
                            National Scholarship for Undergraduate Student (本科生国家奖学金), 2017
                        </li>
                        <li>
                            First Prize of National Mathematical Contest in Modeling (本科生数学建模国家一等奖), 2016
                        </li>
                        <li>
                            Bronze Medal of ACM-ICPC Asia Regional Contest (ACM-ICPC亚洲区域赛铜奖), 2016
                        </li>
                    </ul>
                    <div class="spanner"></div>
                </div>
            </div>
        </div>

        
</ul>



<div style="clear: both;">
    <div class="section">
        <h2>Research Experience </h2>
        <div class="paper">
            <ul>
                <li>
                    Microsoft Research Asia, Beijing, China. <i>Oct.2022-Jan.2023</i><br>
            
                    <ul>
                        <li style="margin-top: 0.3em">
                            Research Intern in Visual Group, mentored by <a href="https://scholar.google.com/citations?user=nZ_PVbsAAAAJ">Zheng Zhang</a>
                        </li>
                        <li>
                            Multi-Modal Knowledge Distillation, Contrastive Language-Image Pretraining
                        </li>
                    </ul>
                </li>
                
                <li>
                    Horizon Robotics, Beijing, China. <i>Aug.2021-Sep.2022</i><br>
                    <ul>
                        <li style="margin-top: 0.3em">
                            Research Intern in Basic Algorithm Platform Department, mentored by <a href="https://scholar.google.com/citations?user=pCY-bikAAAAJ">Qian Zhang</a>
                        </li>
                        <li>
                            Knowledge Distillation, Semantic Segmentation
                        </li>
                    </ul>
                </li>
            
                <li>
                    Megvii, Beijing, China. <i>Nov.2019-Apr.2020</i><br>
                    <ul>
                        <li style="margin-top: 0.3em">
                            Research Intern in Foundation Model Group, mentored by <a href="https://scholar.google.com/citations?user=yuB-cfoAAAAJ">Xiangyu Zhang</a>
                        </li>
                        <li>
                            Knowledge Distillation, Efficient Model Design
                        </li>
                    </ul>
                </li>
            
            </ul>
        </div>

    </div>
</div>







</body>
</html>
